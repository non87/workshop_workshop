{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Dependency to be removed\n",
    "from poibin import PoiBin\n",
    "import pendulum as pend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is something I have readily available from my code.\n",
    "# It will be much simpler for actual workshops\n",
    "def get_goal_ps(ps):\n",
    "    pb = PoiBin(ps)\n",
    "    goals = []\n",
    "    probs = []\n",
    "    g = 0\n",
    "    p = 1\n",
    "    while ((p > 0.01) or (g <= 3)) and (g <= ps.shape[0]):\n",
    "        p = pb.pmf(g)\n",
    "        goals.append(g)\n",
    "        probs.append(p)\n",
    "        g += 1\n",
    "    probs = probs[:-1]\n",
    "    goals = goals[:-1]\n",
    "    return probs, goals\n",
    "\n",
    "dt = pd.read_csv(\"https://git.io/fNmRy\")\n",
    "dt = dt.loc[dt.season == 2017]\n",
    "# For each match, collect the expected goals for each team\n",
    "match_id, time, home_team, i_home, away_team, i_away, goal_home, goal_away, weight = [], [], [], [], [], [], [], [], []\n",
    "# Create a parallel data with only results\n",
    "match_id_only, time_only, home_team_only, i_home_only, away_team_only, i_away_only, goal_home_only, goal_away_only = [], [], [], [], [], [], [], []\n",
    "# Create a dictionary of teams for the i_home/i_away column\n",
    "teams = dt.home.unique()\n",
    "team_dic = {team:i for i, team in enumerate(teams)}\n",
    "\n",
    "\n",
    "matches = dt.groupby('match_id')\n",
    "# Construct the weighted and non-weighted data\n",
    "for i, match in enumerate(matches):\n",
    "    m_id = match[0]\n",
    "    # print(m_id)\n",
    "    match = match[1]\n",
    "    # Get the time in unix timestamp\n",
    "    time_ = pend.parse(match.date.iloc[0])\n",
    "    time_ = time_.int_timestamp\n",
    "    ps = match.loc[match.side=='h', 'xg'].to_numpy()\n",
    "    p_home, g_home = get_goal_ps(ps)\n",
    "    ps = match.loc[match.side=='a', 'xg'].to_numpy()\n",
    "    p_away, g_away = get_goal_ps(ps)\n",
    "    for (g_h, p_h), (g_a, p_a) in product(zip(g_home, p_home), zip(g_away, p_away)):\n",
    "        match_id.append(m_id)\n",
    "        goal_home.append(g_h)\n",
    "        goal_away.append(g_a)\n",
    "        # We should have probabilities high enough for this not to be a problem\n",
    "        weight.append(p_a * p_h)\n",
    "        home_team.append(match.iloc[0, 2])\n",
    "        i_home.append(team_dic[match.iloc[0, 2]])\n",
    "        away_team.append(match.iloc[0, 3])\n",
    "        i_away.append(team_dic[match.iloc[0, 3]])\n",
    "        time.append(time_)\n",
    "    match_id_only.append(m_id)\n",
    "    time_only.append(time_)\n",
    "    home_team_only.append(match.iloc[0, 2])\n",
    "    away_team_only.append(match.iloc[0, 3])\n",
    "    i_home_only.append(team_dic[match.iloc[0, 2]])\n",
    "    i_away_only.append(team_dic[match.iloc[0, 3]])\n",
    "    goal_home_only.append(match.iloc[0,4])\n",
    "    goal_away_only.append(match.iloc[0,5])\n",
    "\n",
    "dt_simple = pd.DataFrame.from_dict({'match_id':match_id_only, 'time':time_only, 'home_team':home_team_only,\n",
    "                                    'away_team':away_team_only, 'goal_home': goal_home_only, 'goal_away':goal_away_only,\n",
    "                                    'i_home':i_home_only, 'i_away': i_away_only})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-journey",
   "metadata": {},
   "source": [
    "### Overall Objective\n",
    "\n",
    "We just read the data for the 2017/2018 English Premier League (EPL) season. The title decider for this season was the match between Man City and Liverpool on ... . Our final objective for this workshop is to create a logistic regression model to predict who will win the match -- and probably the season!\n",
    "\n",
    "\n",
    "To do this, we will first estimate a linear model of how many goals each team score. We will then proceed with a logistic regression predicting the probability that Man City wins. As a background information: each team in EPL play against all other team twice a year. One of the two matches is played \"at home\", the other match is played \"away from home\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-economy",
   "metadata": {},
   "source": [
    "### First Concept\n",
    "\n",
    "Let's run our first model. We will try to model the goal scored by any team as a simple normal distribution. We start with a \"weakly informative\" prior: a normal with mean 0 and sigma 10. We specify the model with a `pm.Deterministic` variable. This is a special kind of variables we will cover more extensively below. For now, it is just a way to signal to `PyMC3` that we actually observe data for that variable.\n",
    "\n",
    "Statistical note. This is a special kind of model: we input a normal distribution (prior) we get an updated normal distribution (posterior). This is the property of conjugacy. These models are helpful because we know their posterior just by math, so we can check our random sampling is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model environment through the with syntax\n",
    "with pm.Model() as normal_conjugate:\n",
    "\n",
    "    # define priors, weakly informative Normal\n",
    "    b0 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    # define the observed part of the model\n",
    "    y  = pm.Deterministic('goals', b0, observed = dt_simple['goal_away'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the prior of the distribution: from mu=0, sigma=10 to mu=1.5 sigma=0.5\n",
    "with pm.Model() as normal_conjugate:\n",
    "    # How do you change this?\n",
    "    b0 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    y  = pm.Deterministic('goals', b0, observed = dt_simple['goal_away'])\n",
    "\n",
    "# Plot the DAG of the model [need to check this is easy to do cross-platform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-cargo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "promotional-isaac",
   "metadata": {},
   "source": [
    "### Second Concept\n",
    "\n",
    "As you can guess, the ability of teams to score are widely different. Having the same normal distribution for everything is not great modeling. Let's single out our two teams and model their scoring with a simple linear regression. \n",
    "\n",
    "Statistical note. We subset the matches up to the big match because we use all available information up to that point. Moreover, we exclude the first game between Man City and Liverpool to preserve independence in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part where I subset the data. perhaps I can even do this offline\n",
    "### Pandas syntax to get the right column \n",
    "obs_goal = dt_simple['goals']\n",
    "team_var = dt_simple['team_var']\n",
    "home_var = dt_simple['home_var']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-encoding",
   "metadata": {},
   "source": [
    "Now we specify the linear model:\n",
    "\n",
    "$Goal = \\beta_0 + \\beta_1 team$\n",
    "\n",
    "where $team$ is a simple indicator whether the team scoring the goal is Manchester city ($team = 1$) or Liverpool ($team = 0$). This is stored in the `team_var` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model environment again\n",
    "with pm.Model() as linear_model:\n",
    "    \n",
    "    # PRIOR PART\n",
    "    # This is the prior for the intercept\n",
    "    b0 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    # This is the prior for the coefficient beta_1 (see equation above)\n",
    "    b1 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    \n",
    "    # LIKELIHOOD and OBSERVATION\n",
    "    y  = pm.Deterministic('goals', b0 + b1*team_var, observed = obs_goal)\n",
    "\n",
    "# PLOT THE MODEL DAG\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-store",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "You can see the linear model is an expansion of the normal model above (see Concept 1). Can you describe the difference in terms of coding?\n",
    "\n",
    "Modify the code above to specify this model:\n",
    "\n",
    "$Goal = \\beta_0 + \\beta_1 team + \\beta_2 home$\n",
    "\n",
    "where $home$ is a simple indicator whether the team considered is playing at home ($home = 1$) or away ($home = 0$). This is stored in the `home_var` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THE CODE\n",
    "with pm.Model() as linear_model:\n",
    "    \n",
    "    # PRIOR PART\n",
    "    # This is the prior for the intercept\n",
    "    b0 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    # This is the prior for the coefficient beta_1\n",
    "    b1 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    \n",
    "    # LIKELIHOOD and OBSERVATION\n",
    "    y  = pm.Deterministic('goals', b0 + b1*team_var, observed = obs_goal)\n",
    "\n",
    "# PLOT THE MODEL DAG\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-bidding",
   "metadata": {},
   "source": [
    "### Third Concept\n",
    "\n",
    "You can use the previous model to calculate the probability that number of goal scored by Liverpool is higher than the goals scored by Man City, or viceversa -- we will come back to this below.\n",
    "\n",
    "But perhaps it is just easier make the model a logistic model of the probability of Man City winning. This requires just two extra steps: the specification of a logistic function as a link function and the use of the probability in a binomial distribution:\n",
    "\n",
    "$\\mathcal{L} = \\beta_0 + \\beta_1 team + \\beta_2 home\\\\\n",
    "\\pi = logit(\\mathcal{L})\\\\\n",
    "Win \\sim Categorical(\\pi) $\n",
    "\n",
    "$\\mathcal{L}$ is the linear part of the model, $logit$ is the link function in GLM parlance (the function that transforms your linear variable into a probability between 0 and 1), $Win$ is a Categorical variable equal to $1$ if the team won."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-lemon",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "As we did above, let's consider the home-away factor for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THE CODE: ADD THE home_var as predictor in the linear part of the model\n",
    "with pm.Model() as linear_model:\n",
    "    \n",
    "    # PRIOR PART\n",
    "    # This is the prior for the intercept\n",
    "    b0 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    # This is the prior for the coefficient beta_1\n",
    "    b1 = pm.Normal(\"b0\", mu=0, sigma=10)\n",
    "    \n",
    "    # LIKELIHOOD and OBSERVATION\n",
    "    # Specify L\n",
    "    L  = b0 + b1*team_var\n",
    "    # Specify Pi\n",
    "    pi = pm.Deterministic('goals', pm.math.invlogit(L))\n",
    "    # Observed outcome (did Man City win?)\n",
    "    L  = pm.Categorical('win', pi, observed = win)\n",
    "\n",
    "# PLOT THE MODEL DAG\n",
    "pm.model_to_graphviz(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
